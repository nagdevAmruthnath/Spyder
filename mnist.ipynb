{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST by pytorch\n",
    "\n",
    "almost the same as https://github.com/pytorch/examples/blob/master/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "import os, sys, shutil, glob, re, time, argparse\n",
    "%matplotlib inline\n",
    "\n",
    "torch.set_printoptions(sci_mode = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:3000px;  \n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:3000px;  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: mnist [-h] [--batch-size N] [--test-batch-size N] [--epochs N]\n",
      "             [--lr LR] [--momentum M] [--no-gpu] [--seed S] [--log-times N]\n",
      "\n",
      "mnist by PyTorch\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help           show this help message and exit\n",
      "  --batch-size N       training batch size (default: 64)\n",
      "  --test-batch-size N  testing batch size (default: 1000)\n",
      "  --epochs N           number of epochs to train (default: 10)\n",
      "  --lr LR              learning rate (default: 0.01)\n",
      "  --momentum M         SGD momentum (default: 0.5)\n",
      "  --no-gpu             not use GPU (cuda)\n",
      "  --seed S             random seed (default: 1)\n",
      "  --log-times N        number of times to log training status per epoch\n",
      "                       (default: 10)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(prog = 'mnist', description = 'mnist by PyTorch')\n",
    "parser.add_argument('--batch-size', type = int, default = 64, metavar = 'N', help = 'training batch size (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type = int, default = 1000, metavar = 'N', help = 'testing batch size (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default = 10, metavar = 'N', help = 'number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default = 0.01, metavar = 'LR', help = 'learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type = float, default = 0.5, metavar = 'M', help = 'SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-gpu', action = 'store_true', help = 'not use GPU (cuda)')\n",
    "parser.add_argument('--seed', type = int, default = 1, metavar = 'S', help='random seed (default: 1)')\n",
    "parser.add_argument('--log-times', type = int, default = 10, metavar = 'N', help='number of times to log training status per epoch (default: 10)')\n",
    "parser.print_help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = torch.load('/media/computer/work/data/MNIST/processed/training.pt')\n",
    "test_data = torch.load('/media/computer/work/data/MNIST/processed/test.pt')\n",
    "\n",
    "train_data = (train_data[0].view(train_data[0].shape[0], -1, train_data[0].shape[1], train_data[0].shape[2]).to(torch.float), train_data[1])\n",
    "test_data  = (test_data[0].view(test_data[0].shape[0], -1, test_data[0].shape[1], test_data[0].shape[2]).to(torch.float), test_data[1])\n",
    "\n",
    "plt.imshow(train_data[0][128][0].numpy(), cmap = \"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        self.fc1 = torch.nn.Linear(4*4*20, 50)\n",
    "        self.fc2 = torch.nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        F = torch.nn.functional\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 4*4*20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train(model, device, train_loader, optimizer, scheduler, epoch, args):\n",
    "    model.train()\n",
    "    total_loss, total_correct = 0, 0\n",
    "    log_batches = np.ceil(np.linspace(0, len(train_loader)-1, args.log_times))\n",
    "    scheduler.step()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        scheduler.optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        scheduler.optimizer.step()\n",
    "        correct = torch.sum(torch.argmax(outputs, dim = 1) == labels)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += correct.item()\n",
    "        if i in log_batches: print('Epoch {} [{}-{}/{}], average loss: {:.6f}, correct: {}/{} ({:.0f}%)'.format(epoch+1, len(inputs)*i+1, len(inputs)*(i+1), len(train_loader.dataset), loss.item(), correct.item(), len(inputs), correct.item()/len(inputs)*100))\n",
    "    print('Summary of Epoch {}, average loss: {:.6f}, correct: {}/{} ({:.0f}%)\\n'.format(epoch+1, total_loss/len(train_loader), total_correct, len(train_loader.dataset), total_correct/len(train_loader.dataset)*100))\n",
    "\n",
    "def test(model, device, test_loader, args):\n",
    "    model.eval()\n",
    "    loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss += torch.nn.functional.cross_entropy(outputs, labels).item()\n",
    "            correct += torch.sum(torch.argmax(outputs, dim = 1) == labels).item()\n",
    "    print('\\nTesting, average loss: {:.6f}, correct: {}/{} ({:.0f}%)\\n'.format(loss/len(test_loader), correct, len(test_loader.dataset), correct/len(test_loader.dataset)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, epochs=4, log_times=10, lr=1e-05, momentum=0.5, no_gpu=False, seed=1, test_batch_size=1000)\n",
      "Epoch 1 [1-64/60000], average loss: 15.749887, correct: 10/64 (16%)\n",
      "Epoch 1 [6721-6784/60000], average loss: 3.634071, correct: 10/64 (16%)\n",
      "Epoch 1 [13377-13440/60000], average loss: 2.318348, correct: 20/64 (31%)\n",
      "Epoch 1 [20033-20096/60000], average loss: 1.820209, correct: 31/64 (48%)\n",
      "Epoch 1 [26689-26752/60000], average loss: 1.870949, correct: 29/64 (45%)\n",
      "Epoch 1 [33345-33408/60000], average loss: 1.667532, correct: 33/64 (52%)\n",
      "Epoch 1 [40001-40064/60000], average loss: 1.591776, correct: 33/64 (52%)\n",
      "Epoch 1 [46657-46720/60000], average loss: 1.451933, correct: 34/64 (53%)\n",
      "Epoch 1 [53313-53376/60000], average loss: 1.235796, correct: 38/64 (59%)\n",
      "Epoch 1 [29985-30016/60000], average loss: 0.910317, correct: 21/32 (66%)\n",
      "Summary of Epoch 1, average loss: 2.394273, correct: 24858/60000 (41%)\n",
      "\n",
      "Epoch 2 [1-64/60000], average loss: 1.398572, correct: 34/64 (53%)\n",
      "Epoch 2 [6721-6784/60000], average loss: 1.248952, correct: 42/64 (66%)\n",
      "Epoch 2 [13377-13440/60000], average loss: 1.116968, correct: 38/64 (59%)\n",
      "Epoch 2 [20033-20096/60000], average loss: 1.210734, correct: 37/64 (58%)\n",
      "Epoch 2 [26689-26752/60000], average loss: 0.970752, correct: 43/64 (67%)\n",
      "Epoch 2 [33345-33408/60000], average loss: 0.890386, correct: 43/64 (67%)\n",
      "Epoch 2 [40001-40064/60000], average loss: 0.893852, correct: 44/64 (69%)\n",
      "Epoch 2 [46657-46720/60000], average loss: 0.870579, correct: 50/64 (78%)\n",
      "Epoch 2 [53313-53376/60000], average loss: 0.918708, correct: 42/64 (66%)\n",
      "Epoch 2 [29985-30016/60000], average loss: 0.625551, correct: 22/32 (69%)\n",
      "Summary of Epoch 2, average loss: 0.999885, correct: 40413/60000 (67%)\n",
      "\n",
      "Epoch 3 [1-64/60000], average loss: 1.133354, correct: 42/64 (66%)\n",
      "Epoch 3 [6721-6784/60000], average loss: 0.947723, correct: 44/64 (69%)\n",
      "Epoch 3 [13377-13440/60000], average loss: 1.179545, correct: 37/64 (58%)\n",
      "Epoch 3 [20033-20096/60000], average loss: 0.657517, correct: 50/64 (78%)\n",
      "Epoch 3 [26689-26752/60000], average loss: 0.906624, correct: 45/64 (70%)\n",
      "Epoch 3 [33345-33408/60000], average loss: 0.549461, correct: 51/64 (80%)\n",
      "Epoch 3 [40001-40064/60000], average loss: 0.735100, correct: 47/64 (73%)\n",
      "Epoch 3 [46657-46720/60000], average loss: 0.685494, correct: 45/64 (70%)\n",
      "Epoch 3 [53313-53376/60000], average loss: 0.564599, correct: 50/64 (78%)\n",
      "Epoch 3 [29985-30016/60000], average loss: 0.529360, correct: 26/32 (81%)\n",
      "Summary of Epoch 3, average loss: 0.744827, correct: 45497/60000 (76%)\n",
      "\n",
      "Epoch 4 [1-64/60000], average loss: 0.660319, correct: 49/64 (77%)\n",
      "Epoch 4 [6721-6784/60000], average loss: 0.591307, correct: 50/64 (78%)\n",
      "Epoch 4 [13377-13440/60000], average loss: 0.825376, correct: 49/64 (77%)\n",
      "Epoch 4 [20033-20096/60000], average loss: 0.539283, correct: 54/64 (84%)\n",
      "Epoch 4 [26689-26752/60000], average loss: 0.571115, correct: 54/64 (84%)\n",
      "Epoch 4 [33345-33408/60000], average loss: 0.603555, correct: 53/64 (83%)\n",
      "Epoch 4 [40001-40064/60000], average loss: 0.448610, correct: 56/64 (88%)\n",
      "Epoch 4 [46657-46720/60000], average loss: 0.704054, correct: 47/64 (73%)\n",
      "Epoch 4 [53313-53376/60000], average loss: 0.552929, correct: 52/64 (81%)\n",
      "Epoch 4 [29985-30016/60000], average loss: 1.034492, correct: 24/32 (75%)\n",
      "Summary of Epoch 4, average loss: 0.615735, correct: 48129/60000 (80%)\n",
      "\n",
      "\n",
      "Testing, average loss: 0.552163, correct: 8245/10000 (82%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args('--epochs 4 --lr 0.00001 --log-times 10'.split())\n",
    "print(args)\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device('cuda' if not args.no_gpu and torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data[0], train_data[1]), args.batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data[0], test_data[1]), args.test_batch_size, num_workers = 4, pin_memory = True)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = args.lr, momentum = args.momentum)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1000)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(args.epochs): \n",
    "    train(model, device, train_loader, optimizer, scheduler, i, args)\n",
    "test(model, device, test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
